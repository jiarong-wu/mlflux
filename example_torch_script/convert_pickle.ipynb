{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8804a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import torch\n",
    "from mlflux.predictor import FluxANNs\n",
    "\n",
    "def open_case (model_dir, model_name):\n",
    "    with open(model_dir + 'config.json', 'r') as f:\n",
    "        config = json.load(f)   \n",
    "    filename = model_dir + model_name\n",
    "    with open(filename, \"rb\") as input_file:\n",
    "        model = pickle.load(input_file)   \n",
    "    model.config = config \n",
    "    return model\n",
    "\n",
    "########## The old way of loading model class through pickles ##########\n",
    "# source_path = '/scratch/jw8736/mlflux/example_python/'\n",
    "# M = open_case(source_path + 'M/', 'm.p')\n",
    "# SH = open_case(source_path + 'SH/', 'sh.p')\n",
    "# LH = open_case(source_path + 'LH/', 'lh.p')\n",
    "# M.__class__\n",
    "# M.__class__.__module__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705e41c3",
   "metadata": {},
   "source": [
    "### Convert previously saved pickle to PyTorch-native binary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d69467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "source_path = '/scratch/jw8736/mlflux/example_python/'\n",
    "target_path = '/scratch/jw8736/mlflux/example_torch_script/'\n",
    "\n",
    "# Apparently change M/SH/LH\n",
    "old_model = open_case(source_path + 'LH/', 'lh.p') # this was a class not good for torch script\n",
    "dir_name = target_path + 'LH/'\n",
    "os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "# Don't use this that save scale and weights seperately, use the one that saves scale and weights together\n",
    "# torch.save(LH.Xscale, dir_name + \"Xscale.pt\")\n",
    "# torch.save(LH.Yscale, dir_name + \"Yscale.pt\")\n",
    "# torch.save(LH.mean_func.state_dict(), dir_name + \"mean_weights.pt\")\n",
    "# torch.save(LH.var_func.state_dict(), dir_name + \"var_weights.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64a6e945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Xmean', 'Xscale', 'Ymean', 'Yscale']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from flux_model import ANN_online\n",
    "\n",
    "####### Convert mean network and save #######\n",
    "# Hard code configuration for now \n",
    "n_in = 5\n",
    "n_out = 1\n",
    "hidden_channels = [32, 16] \n",
    "activation = 'no' # 'exponential' for var\n",
    "mean_ann = ANN_online(n_in=n_in, n_out=n_out, hidden_channels=hidden_channels, ACTIVATION=activation, \n",
    "                      Xmean=old_model.Xscale['mean'], Xscale=old_model.Xscale['scale'], \n",
    "                      Ymean=old_model.Yscale['mean'], Yscale=old_model.Yscale['scale'])\n",
    "# This will miss ['Xmean', 'Xscale', 'Ymean', 'Yscale'] because they were not registered as buffer in the old class\n",
    "missing, unexpected = mean_ann.load_state_dict(old_model.mean_func.state_dict(), strict=False)\n",
    "torch.save(mean_ann.state_dict(), dir_name + \"mean_weights.pt\")\n",
    "print(missing)\n",
    "print(unexpected)\n",
    "\n",
    "####### Convert var network and save #######\n",
    "n_in = 5\n",
    "n_out = 1\n",
    "hidden_channels = [32, 16] \n",
    "activation = 'exponential' # 'exponential' for var\n",
    "var_ann = ANN_online(n_in=n_in, n_out=n_out, hidden_channels=hidden_channels, ACTIVATION=activation, \n",
    "                      Xmean=old_model.Xscale['mean'], Xscale=old_model.Xscale['scale'], \n",
    "                      Ymean=old_model.Yscale['mean'], Yscale=old_model.Yscale['scale'])\n",
    "# This will miss ['Xmean', 'Xscale', 'Ymean', 'Yscale'] because they were not registered as buffer in the old class\n",
    "missing, unexpected = var_ann.load_state_dict(old_model.var_func.state_dict(), strict=False)\n",
    "torch.save(var_ann.state_dict(), dir_name + \"var_weights.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242b6457",
   "metadata": {},
   "source": [
    "### Test loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eacdc5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flux_model import ANN_online\n",
    "import torch\n",
    "target_path = '/scratch/jw8736/mlflux/example_torch_script/'\n",
    "dir_name = target_path + 'LH/'\n",
    "n_in = 5\n",
    "n_out = 1\n",
    "hidden_channels = [32, 16] \n",
    "activation = 'no' # 'exponential' for var\n",
    "state_dict = torch.load(dir_name + \"mean_weights.pt\", map_location=\"cpu\")\n",
    "mean_ann = ANN_online(n_in=n_in, n_out=n_out, hidden_channels=hidden_channels, ACTIVATION=activation, \n",
    "                      Xmean=state_dict['Xmean'], Xscale=state_dict['Xscale'], Ymean=state_dict['Ymean'], Yscale=state_dict['Yscale'])\n",
    "mean_ann.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7429a9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-234.4499]])\n"
     ]
    }
   ],
   "source": [
    "mean_ann.eval()\n",
    "x = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "x = x.reshape(1, -1)\n",
    "with torch.no_grad():\n",
    "    y = mean_ann.forward(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdf1f7d",
   "metadata": {},
   "source": [
    "### Check that it's consistent with old model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6362ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-234.4499]])\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "source_path = '/scratch/jw8736/mlflux/example_python/'\n",
    "target_path = '/scratch/jw8736/mlflux/example_torch_script/'\n",
    "\n",
    "# Apparently change M/SH/LH\n",
    "old_model = open_case(source_path + 'LH/', 'lh.p') # this was a class not good for torch script\n",
    "with torch.no_grad():\n",
    "    y = old_model.pred_mean(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359023a4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9da13e79",
   "metadata": {},
   "source": [
    "### Config dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8e3c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datapath': '/home/jw8736/mlflux/data/Processed/',\n",
       " 'datafile': 'psd_coare3p0_weight1_wave0.nc',\n",
       " 'ann_size': [32, 16],\n",
       " 'mean_activation': 'no',\n",
       " 'var_activation': 'exponential',\n",
       " 'dropout_rate': -1,\n",
       " 'ikeys': ['U', 'tsea', 'tair', 'rh', 'p'],\n",
       " 'okeys': ['taucx'],\n",
       " 'bkeys': ['taubx'],\n",
       " 'RATIO': 0.2,\n",
       " 'WEIGHT': False,\n",
       " 'RESIDUAL': False,\n",
       " 'training_paras': {'batchsize': 1000,\n",
       "  'num_epochs': 4000,\n",
       "  'lr': 0.0005,\n",
       "  'gamma': 0.2,\n",
       "  'EARLYSTOPPING': False,\n",
       "  'patience': 20,\n",
       "  'factor': 0.5,\n",
       "  'max_epochs_without_improvement': 100,\n",
       "  'weight_decay': 1e-05},\n",
       " 'compute_norm': True,\n",
       " 'two_steps': True,\n",
       " 'VERBOSE': True}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Should I read from config \n",
    "# model_dir = '/scratch/jw8736/mlflux/example_python/M/'\n",
    "# with open(model_dir + 'config.json', 'r') as f:\n",
    "#     config = json.load(f)  \n",
    "# hidden_channels = config['ann_size']\n",
    "###### Or should I just hardcode it here\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflux",
   "language": "python",
   "name": "mlflux"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
